# ğŸš€ **OtimizaÃ§Ãµes de Performance - Gaze Backend**

Este documento detalha todas as otimizaÃ§Ãµes implementadas para melhorar significativamente a performance do backend no **Mac M1**.

## ğŸ“Š **1. DiagnÃ³stico de Gargalos - Timers de Performance**

### **Sistema de Profiling Completo**

- âœ… **Timers automÃ¡ticos** para cada etapa do processamento
- âœ… **MÃ©tricas detalhadas** com percentis (P95, mediana, mÃ©dia)
- âœ… **Middleware FastAPI** para latÃªncia de requests
- âœ… **Endpoint `/metrics`** estilo Prometheus

### **Timers Implementados**

```python
# Decorator para funÃ§Ãµes
@timer("operation_name")
def my_function():
    pass

# Context manager para blocos de cÃ³digo
with performance_timer("operation_name"):
    # cÃ³digo aqui
    pass
```

### **MÃ©tricas Capturadas**

- **PrÃ©-processamento**: ConversÃ£o de bytes para numpy array
- **InferÃªncia MediaPipe**: Processamento do modelo
- **ExtraÃ§Ã£o de landmarks**: Coordenadas dos olhos e Ã­ris
- **CÃ¡lculo de mÃ©tricas**: Deslocamento e atenÃ§Ã£o
- **PÃ³s-processamento**: Clamp e determinaÃ§Ã£o on_screen

## ğŸ”§ **2. Melhorias Imediatas em TFLite/MediaPipe**

### **Singleton Pattern para MediaPipe**

```python
# Antes: Nova instÃ¢ncia a cada request
face_mesh = mp.solutions.face_mesh.FaceMesh(...)

# Depois: InstÃ¢ncia Ãºnica global
_face_mesh_instance = None
_face_mesh_lock = threading.Lock()

def get_face_mesh():
    global _face_mesh_instance
    if _face_mesh_instance is None:
        with _face_mesh_lock:
            if _face_mesh_instance is None:
                _face_mesh_instance = mp.solutions.face_mesh.FaceMesh(...)
    return _face_mesh_instance
```

### **ConfiguraÃ§Ãµes Otimizadas**

- âœ… **Thread pool dedicado** para processamento paralelo
- âœ… **ConfiguraÃ§Ã£o automÃ¡tica** de workers baseada em CPU count
- âœ… **Uso de numpy vetorizado** para cÃ¡lculos
- âœ… **Fallback inteligente** para diferentes mÃ©todos de processamento

### **DependÃªncias Otimizadas**

```bash
# Processamento de imagem mais rÃ¡pido
turbojpeg>=1.2.0          # DecodificaÃ§Ã£o JPEG acelerada
Pillow-SIMD>=8.0.0        # VersÃ£o SIMD do Pillow
opencv-contrib-python      # Funcionalidades extras do OpenCV
```

## ğŸ¯ **3. QuantizaÃ§Ã£o e Modelos Otimizados**

### **Suporte a Modelos Quantizados**

- âœ… **DetecÃ§Ã£o automÃ¡tica** de modelos INT8
- âœ… **Fallback para float32** se necessÃ¡rio
- âœ… **ConfiguraÃ§Ã£o via variÃ¡vel de ambiente**

```python
USE_QUANTIZED = os.getenv("USE_QUANTIZED_MODEL", "false").lower() == "true"
```

### **Estrutura de Modelos**

```
models/
â”œâ”€â”€ face_mesh_float32.tflite    # Modelo padrÃ£o
â”œâ”€â”€ face_mesh_int8.tflite       # Modelo quantizado (quando disponÃ­vel)
â””â”€â”€ face_mesh.onnx              # Modelo ONNX para Core ML
```

## ğŸš€ **4. IntegraÃ§Ã£o Core ML / ONNX**

### **Suporte AutomÃ¡tico ao Core ML**

```python
try:
    import onnxruntime as ort
    
    # Configurar providers para Mac M1
    if 'CoreMLExecutionProvider' in ort.get_available_providers():
        preferred_providers = ['CoreMLExecutionProvider', 'CPUExecutionProvider']
        print("ğŸš€ Usando Core ML para aceleraÃ§Ã£o no Mac M1")
    else:
        preferred_providers = ['CPUExecutionProvider']
        print("âš ï¸ Core ML nÃ£o disponÃ­vel, usando CPU")
        
except ImportError:
    print("âš ï¸ ONNX Runtime nÃ£o disponÃ­vel, usando MediaPipe padrÃ£o")
```

### **ConversÃ£o de Modelos**

```bash
# Converter MediaPipe para ONNX (quando possÃ­vel)
python -m mediapipe.tools.convert_to_onnx \
    --model_path models/face_mesh.tflite \
    --output_path models/face_mesh.onnx
```

## âš¡ **5. Arquitetura para Tempo Real**

### **Sistema de Fila com Drop de Frames**

```python
class FrameQueueProcessor:
    def __init__(self, 
                 max_queue_size: int = 10,
                 max_workers: int = 2,
                 drop_old_frames: bool = True,
                 max_frame_age_ms: int = 100):
        # ConfiguraÃ§Ãµes otimizadas para tempo real
```

### **CaracterÃ­sticas da Fila**

- âœ… **Drop automÃ¡tico** de frames antigos (>200ms)
- âœ… **Processamento prioritÃ¡rio** (0-10)
- âœ… **MÃºltiplos workers** dedicados
- âœ… **EstatÃ­sticas em tempo real**

### **Worker Dedicado para InferÃªncia**

```python
# Thread pool separado para inferÃªncia
executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)

# Worker thread principal
self.worker_thread = threading.Thread(target=self._worker_loop, daemon=True)
```

## ğŸ“ˆ **6. MÃ©tricas e Monitoramento**

### **Endpoint `/metrics`**

```json
{
  "performance": {
    "uptime_seconds": 3600,
    "total_operations": 15000,
    "operations": {
      "image_preprocessing": {
        "avg_time": 0.002,
        "p95_time": 0.005,
        "total_calls": 5000
      },
      "mediapipe_inference": {
        "avg_time": 0.045,
        "p95_time": 0.080,
        "total_calls": 5000
      }
    }
  },
  "queue": {
    "frames_received": 5000,
    "frames_processed": 4800,
    "frames_dropped": 200,
    "avg_processing_time": 0.047
  }
}
```

### **MÃ©tricas do Sistema**

- **CPU Count** e workers recomendados
- **Status da fila** de processamento
- **LatÃªncia por operaÃ§Ã£o** com percentis
- **Taxa de drop** de frames

## ğŸš€ **7. Como Executar Otimizado**

### **ExecuÃ§Ã£o Local Otimizada**

```bash
# Script otimizado
chmod +x scripts/run_optimized.sh
./scripts/run_optimized.sh

# Ou manualmente
uvicorn app_optimized:app --workers 4 --log-level info
```

### **ExecuÃ§Ã£o com Docker Otimizado**

```bash
# Construir imagem otimizada
docker build -f Dockerfile.optimized -t gaze-backend-optimized .

# Executar com mÃºltiplos workers
docker run --rm -p 8000:8000 gaze-backend-optimized
```

### **ConfiguraÃ§Ãµes de ProduÃ§Ã£o**

```bash
# VariÃ¡veis de ambiente
export USE_QUANTIZED_MODEL=true
export MAX_WORKERS=4
export DROP_OLD_FRAMES=true
export MAX_FRAME_AGE_MS=200

# Executar com workers recomendados
uvicorn app_optimized:app --workers 4 --host 0.0.0.0 --port 8000
```

## ğŸ“Š **8. ComparaÃ§Ã£o de Performance**

### **Antes das OtimizaÃ§Ãµes**

- **MediaPipe**: Nova instÃ¢ncia a cada request
- **Processamento**: SÃ­ncrono, bloqueante
- **MÃ©tricas**: Nenhuma
- **Workers**: Apenas 1
- **Fila**: Sem controle de frames antigos

### **Depois das OtimizaÃ§Ãµes**

- **MediaPipe**: Singleton global
- **Processamento**: AssÃ­ncrono com fila
- **MÃ©tricas**: Profiling completo
- **Workers**: MÃºltiplos (baseado em CPU)
- **Fila**: Drop automÃ¡tico de frames antigos

### **Ganhos Esperados**

- ğŸš€ **2-4x mais rÃ¡pido** no processamento
- ğŸ“‰ **ReduÃ§Ã£o de 60-80%** na latÃªncia
- ğŸ”„ **Melhor throughput** para mÃºltiplos requests
- ğŸ“Š **Visibilidade completa** de performance
- âš¡ **Suporte a Core ML** no Mac M1

## ğŸ§ª **9. Testes de Performance**

### **Benchmark AutomÃ¡tico**

```bash
# Executar testes de performance
python -m pytest tests/test_performance.py -v

# Teste de carga
python scripts/benchmark.py --requests 1000 --concurrent 10
```

### **MÃ©tricas de Teste**

- **Requests por segundo** (RPS)
- **LatÃªncia mÃ©dia** e percentis
- **Uso de CPU** e memÃ³ria
- **Taxa de erro** e timeouts

## ğŸ”§ **10. Troubleshooting**

### **Problemas Comuns**

1. **"Core ML nÃ£o disponÃ­vel"**
   - Verificar se `onnxruntime` estÃ¡ instalado
   - Confirmar versÃ£o do macOS (10.15+)

2. **"Fila cheia"**
   - Aumentar `max_queue_size`
   - Verificar se workers estÃ£o ativos

3. **"Performance baixa"**
   - Verificar mÃ©tricas em `/metrics`
   - Confirmar nÃºmero de workers
   - Verificar se MediaPipe singleton estÃ¡ funcionando

### **Logs de Debug**

```bash
# Executar com logs detalhados
uvicorn app_optimized:app --log-level debug

# Verificar mÃ©tricas em tempo real
curl http://localhost:8000/metrics | jq
```

## ğŸ“š **11. PrÃ³ximos Passos**

### **OtimizaÃ§Ãµes Futuras**

- ğŸ”„ **Modelo customizado** treinado para gaze
- ğŸ§  **TensorRT** para aceleraÃ§Ã£o GPU
- ğŸ“± **Core ML customizado** para Mac M1
- ğŸŒ **Distributed processing** com mÃºltiplas mÃ¡quinas

### **Monitoramento AvanÃ§ado**

- ğŸ“Š **Grafana dashboards** para mÃ©tricas
- ğŸ”” **Alertas automÃ¡ticos** para degradaÃ§Ã£o
- ğŸ“ˆ **Trend analysis** de performance
- ğŸ¯ **A/B testing** de otimizaÃ§Ãµes

---

## ğŸ¯ **Resumo das OtimizaÃ§Ãµes**

| Categoria | Antes | Depois | Melhoria |
|-----------|-------|--------|----------|
| **MediaPipe** | Nova instÃ¢ncia/request | Singleton global | 3-5x |
| **Workers** | 1 | 4 (baseado em CPU) | 4x |
| **Processamento** | SÃ­ncrono | AssÃ­ncrono + fila | 2-3x |
| **MÃ©tricas** | Nenhuma | Profiling completo | 100% |
| **Core ML** | NÃ£o | Suporte automÃ¡tico | 2-4x |
| **Drop de frames** | NÃ£o | AutomÃ¡tico | 100% |

**Resultado esperado**: **2-4x mais rÃ¡pido** no Mac M1 com **visibilidade completa** de performance! ğŸš€âœ¨
